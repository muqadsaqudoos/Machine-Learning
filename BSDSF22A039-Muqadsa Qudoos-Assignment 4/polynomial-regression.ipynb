{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RM  LSTAT  PTRATIO      MEDV\n",
      "0  6.575   4.98     15.3  504000.0\n",
      "1  6.421   9.14     17.8  453600.0\n",
      "2  7.185   4.03     17.8  728700.0\n",
      "3  6.998   2.94     18.7  701400.0\n",
      "4  7.147   5.33     18.7  760200.0\n",
      "RM         0\n",
      "LSTAT      0\n",
      "PTRATIO    0\n",
      "MEDV       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "df = pd.read_csv('housing.csv')\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['RM', 'LSTAT', 'PTRATIO']]\n",
    "y = df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_poly = pd.DataFrame(X_poly, columns=poly.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    adj_r2_train = 1 - (1 - r2_train) * (len(y_train) - 1) / (len(y_train) - X_train.shape[1] - 1)\n",
    "    adj_r2_test = 1 - (1 - r2_test) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "    return r2_train, adj_r2_train, r2_test, adj_r2_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep All Variables\n",
    "r2_all, adj_r2_all, r2_test_all, adj_r2_test_all = evaluate_model(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Backward Elimination\n",
    "X_train_be = sm.add_constant(X_train)\n",
    "X_test_be = sm.add_constant(X_test)\n",
    "model_be = sm.OLS(y_train, X_train_be).fit()\n",
    "p_values = model_be.pvalues\n",
    "selected_features = X_train.columns[p_values[1:] < 0.05]\n",
    "X_train_be = X_train[selected_features]\n",
    "X_test_be = X_test[selected_features]\n",
    "r2_be, adj_r2_be, r2_test_be, adj_r2_test_be = evaluate_model(X_train_be, X_test_be, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Forward Selection\n",
    "selected_features = []\n",
    "remaining_features = list(X_train.columns)\n",
    "best_adj_r2 = -np.inf\n",
    "while remaining_features:\n",
    "    adj_r2_candidates = {}\n",
    "    for feature in remaining_features:\n",
    "        X_train_fs = X_train[selected_features + [feature]]\n",
    "        X_test_fs = X_test[selected_features + [feature]]\n",
    "        _, adj_r2_train, _, adj_r2_test = evaluate_model(X_train_fs, X_test_fs, y_train, y_test)\n",
    "        adj_r2_candidates[feature] = adj_r2_test\n",
    "    best_feature = max(adj_r2_candidates, key=adj_r2_candidates.get)\n",
    "    if adj_r2_candidates[best_feature] > best_adj_r2:\n",
    "        selected_features.append(best_feature)\n",
    "        best_adj_r2 = adj_r2_candidates[best_feature]\n",
    "        remaining_features.remove(best_feature)\n",
    "    else:\n",
    "        break\n",
    "X_train_fs = X_train[selected_features]\n",
    "X_test_fs = X_test[selected_features]\n",
    "r2_fs, adj_r2_fs, r2_test_fs, adj_r2_test_fs = evaluate_model(X_train_fs, X_test_fs, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = []\n",
    "remaining_features = list(X_train.columns)\n",
    "best_adj_r2 = -np.inf\n",
    "while remaining_features:\n",
    "    adj_r2_candidates = {}\n",
    "    for feature in remaining_features:\n",
    "        X_train_bs = X_train[selected_features + [feature]]\n",
    "        X_test_bs = X_test[selected_features + [feature]]\n",
    "        _, adj_r2_train, _, adj_r2_test = evaluate_model(X_train_bs, X_test_bs, y_train, y_test)\n",
    "        adj_r2_candidates[feature] = adj_r2_test\n",
    "    best_feature = max(adj_r2_candidates, key=adj_r2_candidates.get)\n",
    "    if adj_r2_candidates[best_feature] > best_adj_r2:\n",
    "        selected_features.append(best_feature)\n",
    "        best_adj_r2 = adj_r2_candidates[best_feature]\n",
    "        remaining_features.remove(best_feature)\n",
    "        while len(selected_features) > 1:  # Ensure at least one feature remains\n",
    "            adj_r2_candidates = {}\n",
    "            for feature in selected_features:\n",
    "                temp_features = selected_features.copy()\n",
    "                temp_features.remove(feature)\n",
    "                X_train_bs = X_train[temp_features]\n",
    "                X_test_bs = X_test[temp_features]\n",
    "                _, adj_r2_train, _, adj_r2_test = evaluate_model(X_train_bs, X_test_bs, y_train, y_test)\n",
    "                adj_r2_candidates[feature] = adj_r2_test\n",
    "            worst_feature = min(adj_r2_candidates, key=adj_r2_candidates.get)\n",
    "            if adj_r2_candidates[worst_feature] < best_adj_r2:\n",
    "                selected_features.remove(worst_feature)\n",
    "                best_adj_r2 = adj_r2_candidates[worst_feature]\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "X_train_bs = X_train[selected_features]\n",
    "X_test_bs = X_test[selected_features]\n",
    "r2_bs, adj_r2_bs, r2_test_bs, adj_r2_test_bs = evaluate_model(X_train_bs, X_test_bs, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Keep All Variables: R²=0.8378, Adjusted R²=0.8340\n",
      "Backward Elimination: R²=0.8370, Adjusted R²=0.8340\n",
      "Forward Selection: R²=0.8086, Adjusted R²=0.8066\n",
      "Bidirectional Selection: R²=0.0039, Adjusted R²=0.0014\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Keep All Variables: R²={r2_all:.4f}, Adjusted R²={adj_r2_all:.4f}\")\n",
    "print(f\"Backward Elimination: R²={r2_be:.4f}, Adjusted R²={adj_r2_be:.4f}\")\n",
    "print(f\"Forward Selection: R²={r2_fs:.4f}, Adjusted R²={adj_r2_fs:.4f}\")\n",
    "print(f\"Bidirectional Selection: R²={r2_bs:.4f}, Adjusted R²={adj_r2_bs:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
